@online{andersonVisionandLanguageNavigationInterpreting2018,
  title = {Vision-and-{{Language Navigation}}: {{Interpreting}} Visually-Grounded Navigation Instructions in Real Environments},
  shorttitle = {Vision-and-{{Language Navigation}}},
  author = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and Sünderhauf, Niko and Reid, Ian and Gould, Stephen and family=Hengel, given=Anton, prefix=van den, useprefix=false},
  date = {2018-04-05},
  eprint = {1711.07280},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1711.07280},
  urldate = {2023-08-13},
  abstract = {A robot that can carry out a natural-language instruction has been a dream since before the Jetsons cartoon series imagined a life of leisure mediated by a fleet of attentive robot helpers. It is a dream that remains stubbornly distant. However, recent advances in vision and language methods have made incredible progress in closely related areas. This is significant because a robot interpreting a natural-language navigation instruction on the basis of what it sees is carrying out a vision and language process that is similar to Visual Question Answering. Both tasks can be interpreted as visually grounded sequence-to-sequence translation problems, and many of the same methods are applicable. To enable and encourage the application of vision and language methods to the problem of interpreting visually-grounded navigation instructions, we present the Matterport3D Simulator -- a large-scale reinforcement learning environment based on real imagery. Using this simulator, which can in future support a range of embodied vision and language tasks, we provide the first benchmark dataset for visually-grounded natural language navigation in real buildings -- the Room-to-Room (R2R) dataset.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {C\:\\Users\\qq376\\Zotero\\storage\\AJGFB47F\\Anderson 等 - 2018 - Vision-and-Language Navigation Interpreting visua.pdf;C\:\\Users\\qq376\\Zotero\\storage\\GIRWBT3D\\Anderson et al_2018_Vision-and-Language Navigation.pdf;C\:\\Users\\qq376\\Zotero\\storage\\PP9CKTQT\\1711.html}
}
